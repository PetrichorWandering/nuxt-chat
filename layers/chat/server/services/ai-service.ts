import OpenAI from "openai";

export interface AIMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface ChatCompletionResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }>;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface ChatAnswer {
  content: string;         // å›ç­”å†…å®¹
  requestId?: string;      // è¯·æ±‚ ID
  tokens?: number;         // æ€» token æ•°
  promptTokens?: number;   // æç¤º tokens
  completionTokens?: number; // å›ç­” tokens
}

const { dashscopeApiKey, dashscopeBaseURL } = useRuntimeConfig();

const qwenModle = new OpenAI({
  apiKey: dashscopeApiKey,
  baseURL: dashscopeBaseURL,
})

/**
 * åƒé—®æ¨¡å‹è°ƒç”¨æ–¹æ³•
 * @param messages æ¶ˆæ¯æ•°ç»„
 * @param model æ¨¡å‹åç§°
 * @returns æ¨¡å‹å“åº”
 */
async function callQwenModel(
  messages: AIMessage[],
  model: string = "qwen-turbo-2025-07-15",
): Promise<ChatAnswer> {
  const response = await qwenModle.chat.completions.create({
    model,
    messages,
  }) as ChatCompletionResponse;

  if (!response || !Array.isArray(response.choices) || response.choices.length === 0) {
    throw new Error("Empty or invalid response from model.");
  }

  const content = response.choices[0]?.message?.content?.trim();
  if (!content) {
    throw new Error("Response content is empty.");
  }

  const result: ChatAnswer = {
      content: response.choices[0].message.content.trim(),
      requestId: response.id,
      tokens: response.usage?.total_tokens,
      promptTokens: response.usage?.prompt_tokens,
      completionTokens: response.usage?.completion_tokens,
    };
    
    console.info(
      `[ğŸ¤– Qwen Model Chat] requestId=${result.requestId}, 
      tokens(total=${result.tokens}, prompt=${result.promptTokens}, completion=${result.completionTokens})`
    );

  return result;
}


/**
 * ç”ŸæˆèŠå¤©å“åº”
 * @param chatMessages èŠå¤©æ¶ˆæ¯æ•°ç»„
 * @returns èŠå¤©å“åº”å†…å®¹
 */
export async function generateChatResponse(
  chatMessages: AIMessage[],
): Promise<string> {
  try {
    const response = await callQwenModel(chatMessages)
    return response.content;
  } catch (error) {
    console.error("generateChatResponse error:", error);
    return "âŒ ç”Ÿæˆå›ç­”å¤±è´¥ï¼Œè¯·ç¨åå†è¯•";
  }
}

/**
 * ç”ŸæˆèŠå¤©æ ‡é¢˜
 * @param firstMessage èŠå¤©æ¶ˆæ¯æ•°ç»„çš„ç¬¬ä¸€ä¸ªæ¶ˆæ¯
 * @returns èŠå¤©æ ‡é¢˜
 */
export async function generateChatTitle(
  firstMessage: string
): Promise<string> {
  try {
    const messages:AIMessage[] = [
      {
        role: 'system',
        content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ ‡é¢˜ç”Ÿæˆå™¨ï¼Œè¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®çš„æ ‡é¢˜ã€‚

è¦æ±‚ï¼š
1. æ ‡é¢˜é•¿åº¦æ§åˆ¶åœ¨14ä¸ªå­—ç¬¦å†…
2. ç›´æ¥è¿”å›æ ‡é¢˜å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å‰ç¼€æˆ–è§£é‡Š
3. æ ‡é¢˜åº”è¯¥æ˜¯ç”¨æˆ·è¾“å…¥çš„æ ¸å¿ƒå†…å®¹æˆ–è€…ç”¨æˆ·çš„æ„å›¾çš„æ¦‚æ‹¬
4. ç”Ÿæˆæ ‡é¢˜æ‰€ä½¿ç”¨çš„è¯­è¨€å’Œç”¨æˆ·è¾“å…¥å†…å®¹è¯­è¨€ä¿æŒä¸€è‡´

ç¤ºä¾‹ï¼š
ç”¨æˆ·è¾“å…¥ï¼šä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
è¾“å‡ºï¼šå¤©æ°”å’¨è¯¢

ç”¨æˆ·è¾“å…¥ï¼šä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼Ÿ
è¾“å‡ºï¼šè‡ªæˆ‘ä»‹ç»

ç”¨æˆ·è¾“å…¥ï¼š1,3,5,7 åä¸€ä¸ªæ•°å­—åº”è¯¥æ˜¯ä»€ä¹ˆ
è¾“å‡ºï¼šåºåˆ—é¢„æµ‹`,
      },
      {
        role: 'user',
        content: firstMessage,
      },
    ];

    const response = await callQwenModel(messages);
    return response.content;
  } catch (error) {
    console.error("generateChatTitle error:", error);
    return "æ–°å¯¹è¯";
  }
}
